name: mcp_things2

services:
  # Core MCP Services (keep these)
  sandbox:
    image: mcp_things2-sandbox:latest
    build:
      context: ./sandbox
      dockerfile: Dockerfile
    healthcheck:
      test: ["CMD", "/venv/bin/python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8001/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
    environment:
      - PYTHONPATH=/app

  time-client:
    image: mcp_things2-time-client:latest
    build:
      context: ./time-client
      dockerfile: Dockerfile
    healthcheck:
      test: ["CMD", "/venv/bin/python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8003/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
    environment:
      - PYTHONPATH=/app

  # LLM Engine
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ${HOME}/docker-data/ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped

  # MCP-to-OpenAPI Bridge
  mcpo:
    image: ghcr.io/open-webui/mcpo:main
    ports:
      - "8080:8080"
    volumes:
      - ./mcpo-config.json:/app/config.json:ro
    command: ["serve", "--port", "8080", "--api-key", "your-secret-key", "--config", "/app/config.json"]
    depends_on:
      time-client:
        condition: service_healthy
      sandbox:
        condition: service_healthy
      diffusion-api:
        condition: service_started

  # AI Image Generation API
  diffusion-api:
    image: mcp_things2-diffusion-api:latest
    build:
      context: ./diffusion-api
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./diffusion-api/models/sdxl:/app/models/sdxl:ro
      - ./diffusion-api/models/tokenizers:/app/models/tokenizers:ro
      - ./diffusion-api/sdxl_styles:/app/sdxl_styles:ro
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - PYTHONPATH=/app


  # Style Browser Web Interface
  style-browser:
    image: mcp_things2-style-browser:latest
    build:
      context: ./style-browser
      dockerfile: Dockerfile
    ports:
      - "8081:8080"
    environment:
      - DIFFUSION_API_URL=http://diffusion-api:8000
    depends_on:
      diffusion-api:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Chat Interface
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "3001:8080"  # Using 3001 to avoid conflict with Grafana
    volumes:
      - ./data/open-webui:/app/backend/data
    environment:
      - OPENAI_API_BASE_URL=https://api.openai.com/v1
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ENABLE_OPENAI_API=true
    depends_on:
      ollama:
        condition: service_started
      mcpo:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring Services (kept these!)
  # prometheus:
  #   image: prom/prometheus:latest
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
  #     - ./data/prometheus:/prometheus
  #   command:
  #     - '--config.file=/etc/prometheus/prometheus.yml'
  #     - '--storage.tsdb.path=/prometheus'
  #     - '--web.console.libraries=/etc/prometheus/console_libraries'
  #     - '--web.console.templates=/etc/prometheus/consoles'
  #     - '--web.enable-lifecycle'
  #   healthcheck:
  #     test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3

  # grafana:
  #   image: grafana/grafana:latest
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     - GF_SECURITY_ADMIN_PASSWORD=admin
  #     - GF_USERS_ALLOW_SIGN_UP=false
  #   volumes:
  #     - ./data/grafana:/var/lib/grafana
  #     - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
  #     - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
  #   depends_on:
  #     prometheus:
  #       condition: service_healthy
  #   healthcheck:
  #     test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3 